{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week06_MultilinearRegression",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJoQYu4pTaJUAD8R53FSuk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ch00226855/CMP414765Spring2021/blob/main/Week06_MultilinearRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXhaotNQxr2w"
      },
      "source": [
        "# Week 6\r\n",
        "# Multilinear Regression\r\n",
        "\r\n",
        "Last time we looked at a simple linear regression model $sales = \\beta_0 + \\beta_1\\cdot\\textit{TV advertising budget}$. More generally, a linear model makes a prediction by computing a weighted sum of their input features (plus a constant).\r\n",
        "\r\n",
        "**Reading: Chapter 4**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81lHyTpwx0zu"
      },
      "source": [
        "## Multilinear Regression: Model Assumptions\r\n",
        "**Model**:\r\n",
        "\r\n",
        "$\\hat{y} = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 +\\cdots + \\theta_nx_n$\r\n",
        "1. $\\hat{y}$ is the predicted value.\r\n",
        "2. $n$ is the number of features.\r\n",
        "3. $x_i$ is the i-th feature value.\r\n",
        "4. $\\theta_j$ is the j-th model parameter (associated with $x_j$)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azLxHqqUx02U"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb5RGmIdx04v",
        "outputId": "cc5cb8d7-16d4-4a05-c812-f55143c12ce9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "# Toy example\r\n",
        "columns = ['Homework', 'Midterm', 'Final']\r\n",
        "data = pd.DataFrame({\r\n",
        "    \"Homework\": [95, 70, 80, 100, 70],\r\n",
        "    \"Midterm\": [90, 60, 80, 80, 85],\r\n",
        "    \"Final\": [93, 66, 85, 60, 90]\r\n",
        "}, index=[\"Alice\", \"Bob\", \"Clare\", \"David\", \"Eve\"])\r\n",
        "\r\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Homework</th>\n",
              "      <th>Midterm</th>\n",
              "      <th>Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Alice</th>\n",
              "      <td>95</td>\n",
              "      <td>90</td>\n",
              "      <td>93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bob</th>\n",
              "      <td>70</td>\n",
              "      <td>60</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Clare</th>\n",
              "      <td>80</td>\n",
              "      <td>80</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>David</th>\n",
              "      <td>100</td>\n",
              "      <td>80</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Eve</th>\n",
              "      <td>70</td>\n",
              "      <td>85</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Homework  Midterm  Final\n",
              "Alice        95       90     93\n",
              "Bob          70       60     66\n",
              "Clare        80       80     85\n",
              "David       100       80     60\n",
              "Eve          70       85     90"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKguV_HWx09V"
      },
      "source": [
        "In this case:\r\n",
        "- $x_1$ is the homework feature\r\n",
        "- $x_2$ is the midterm feature\r\n",
        "- $y$ is the final feature\r\n",
        "- model is: $final = \\theta_0 + \\theta_1 * homework + \\theta_2 * midterm$\r\n",
        "- We need to come up with values for $\\theta_0, \\theta_1, \\theta_2$ to complete the model.\r\n",
        "\r\n",
        "**Objective**: Suppose that another student Fred has Homework score 85 and Midterm score 80. What is prediction of his final exam score?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txFgiEHAx0_q"
      },
      "source": [
        "## Multilinear Regression: Vectorized form\r\n",
        "\r\n",
        "The multilinear model can also be written as:\r\n",
        "\r\n",
        "**$\\hat{y} = \\theta\\cdot\\textbf{x}$**.\r\n",
        "1. $\\theta = (\\theta_0, \\theta_1, ..., \\theta_n)$ is the paramter vector.\r\n",
        "2. $\\textbf{x} = (1, x_1, ..., x_n)$ is the feature vector.\r\n",
        "3. The symbol $\\cdot$ represents the inner-product of two vectors. For example, $(1, 2, 3)\\cdot (4, 5, 6) = 1\\times 4 + 2\\times 5 + 3\\times 6 = 32$.\r\n",
        "\r\n",
        "**Why is the expression $\\theta\\cdot\\textbf{x}$ equivalent to $\\theta_0 + \\theta_1x_1 + \\theta_2x_2 +\\cdots + \\theta_nx_n$?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8Acxyvfx1CF",
        "outputId": "35a2547a-85e3-4cd5-e1d6-3f27090f0802",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Let's apply the linear regression tool in sci-kit learn on the toy example\r\n",
        "from sklearn.linear_model import LinearRegression\r\n",
        "\r\n",
        "model_lr = LinearRegression()\r\n",
        "\r\n",
        "model_lr.fit(data[[\"Homework\", \"Midterm\"]], data[[\"Final\"]]) \r\n",
        "# The input data requires two layers of brackets because the input features should be expressed as a list."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoD9GMG1x1Em",
        "outputId": "27c24500-081d-44ba-bd6a-f8c65d7aea42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Retrieve the estimated parameter values.\r\n",
        "print(\"Theta 0:\", model_lr.intercept_)\r\n",
        "print(\"Theta 1 and Theta 2:\", model_lr.coef_)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Theta 0: [35.]\n",
            "Theta 1 and Theta 2: [[-0.71627907  1.30697674]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcqnAPn8Hd6E",
        "outputId": "296fa58b-4c5a-4ac6-bfe5-0856c807f8fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Apply the model to provide prediction for Fred\r\n",
        "model_lr.predict([[85, 80],\r\n",
        "                  [60, 60]])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[78.6744186 ],\n",
              "       [70.44186047]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYP9E1UoIBNp",
        "outputId": "73bccbda-3272-473c-d5be-1596869673fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Remember prediction = theta0 + theta1 * homework + theta2 * midterm\r\n",
        "theta0 = 35\r\n",
        "theta1 = -0.716\r\n",
        "theta2 = 1.307\r\n",
        "\r\n",
        "prediction = theta0 + theta1 * 60 + theta2 * 60\r\n",
        "print(prediction)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "70.46000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFWHQvs4IkxU",
        "outputId": "ce4345cf-d7f7-4c73-c23c-51eb0e3c4172",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Let's use the vector form to get the prediction.\r\n",
        "# prediction = inner-product of the parameter vector and the feature vector.\r\n",
        "parameter_vector = np.array([35, -0.716, 1.307])\r\n",
        "feature_vector = np.array([1, 60, 60])\r\n",
        "\r\n",
        "prediction = parameter_vector.dot(feature_vector)\r\n",
        "\r\n",
        "print(prediction)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "70.46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwJG44-7x1HE"
      },
      "source": [
        "## Multilinear Regression: Cost Function\r\n",
        "In order to calculate the best value for each parameter, we need a **cost function** that evaluates the errors made by a give set of parameter values. Here we use the **mean squared error (MSE)** function as the cost function:\r\n",
        "\r\n",
        "$J(\\textbf{X}, \\theta) = \\frac{1}{m}\\sum_{i=1}^{m}\\big(\\theta\\cdot\\textbf{x}^{(i)} - y^{(i)}\\big)^2$\r\n",
        "\r\n",
        "Here $(\\textbf{x}^{(i)}, y^{(i)})$ represents the i-th training example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uh-Zy_vEx1JZ",
        "outputId": "eecba555-f48b-47f6-cdf3-3d378cca8f65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Calculate the MSE cost of the toy example for the parameter values given by sci-kit learn.\r\n",
        "\r\n",
        "theta = np.array([35, -0.716, 1.307])\r\n",
        "\r\n",
        "list_errors = []\r\n",
        "\r\n",
        "for i in data.index:\r\n",
        "    # print(i)\r\n",
        "    x = np.array([1, data.loc[i, \"Homework\"], data.loc[i, \"Midterm\"]])\r\n",
        "    theta_dot_x = theta.dot(x)\r\n",
        "    y = data.loc[i, \"Final\"]\r\n",
        "    squared_error = (theta_dot_x - y) ** 2\r\n",
        "    list_errors.append(squared_error)\r\n",
        "\r\n",
        "print(list_errors)\r\n",
        "print(\"MSE:\", np.mean(list_errors))\r\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[70.39210000000001, 7.290000000000015, 7.398399999999993, 63.361600000000124, 35.70062499999993]\n",
            "MSE: 36.82854500000002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG2rW2SNx1Lw"
      },
      "source": [
        "## Multilinear Regression: Training Algorithm 1\r\n",
        "The value of $\\theta$ that minimizes the cost function is given by the following **normal equation**:\r\n",
        "\r\n",
        "$\\hat{\\theta} = \\big(\\textbf{X}^T\\cdot\\textbf{X}\\big)^{-1}\\cdot\\textbf{X}^T\\cdot\\textbf{y}$.\r\n",
        "\r\n",
        "1. $\\textbf{X}$ is an $m\\times (n+1)$ matrix whose i-th row is $\\textbf{x}^{(i)}$.\r\n",
        "$$\\textbf{X} = \\begin{pmatrix}\r\n",
        "1 & x^{(1)}_1 & x^{(1)}_2 & \\cdots & x^{(1)}_n \\\\\r\n",
        "1 & x^{(2)}_1 & x^{(2)}_2 & \\cdots & x^{(2)}_n \\\\\r\n",
        "\\vdots & \\vdots &\\vdots & \\ddots & \\vdots \\\\\r\n",
        "1 & x^{(m)}_1 & x^{(m)}_2 & \\cdots & x^{(m)}_n \\\\\r\n",
        "\\end{pmatrix}$$\r\n",
        "2. $$\\textbf{y} = \\begin{pmatrix}y^{(1)} \\\\ \\vdots \\\\ y^{(m)}\\end{pmatrix}$$.\r\n",
        "3. The cost function $J(\\theta)$ also has a matrix expression\r\n",
        "$$J(\\theta) = \\frac{1}{m}(\\textbf{X}^T\\cdot\\theta - \\textbf{y})^T\\cdot (\\textbf{X}^T\\cdot\\theta - \\textbf{y})$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0r86Sigx1OO",
        "outputId": "dfdc1030-9f50-4ec2-8214-b84cefb01c0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Construct matrix X using np.hstack(), np.ones()\r\n",
        "\r\n",
        "# 1. Construct a column of ones\r\n",
        "\r\n",
        "X = np.hstack([np.ones([5, 1]), data[[\"Homework\", \"Midterm\"]].values])\r\n",
        "print(X)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  1.  95.  90.]\n",
            " [  1.  70.  60.]\n",
            " [  1.  80.  80.]\n",
            " [  1. 100.  80.]\n",
            " [  1.  70.  85.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIZZCIicx1Q7",
        "outputId": "bef904d7-fe43-4e64-cc3d-6ecd7252d335",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Construct vector y\r\n",
        "y = data[[\"Final\"]].values\r\n",
        "print(y)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[93]\n",
            " [66]\n",
            " [85]\n",
            " [60]\n",
            " [90]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "197CDh19x1Th",
        "outputId": "ac316d69-eef0-43fc-af6b-00013e460a3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Apply the normal equation to find theta\r\n",
        "\r\n",
        "theta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\r\n",
        "\r\n",
        "print(\"Theta:\", theta)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Theta: [[35.        ]\n",
            " [-0.71627907]\n",
            " [ 1.30697674]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ezXjZlvx1WG"
      },
      "source": [
        "## Multilinear Regression: Training Algorithm 2\r\n",
        "The normal equation is not applicable when $\\textbf{X}^T\\cdot\\textbf{X}$ is not invertible. It happens if:\r\n",
        "- Several features are linearly dependent (for example, feature3 = feature1 + feature2)\r\n",
        "- The number of features is greater than the number of training data (for example, DNA data)\r\n",
        "\r\n",
        "When the matrix $\\textbf{X}$ is too large, the normal equation may take too long to finish since it requires a matrix multiplication.\r\n",
        "\r\n",
        "In these cases, we can use the **gradient descent** method to minimize the cost function instead.\r\n",
        "\r\n",
        "Gradient descent with one variable ideally looks like this:\r\n",
        "<img src=\"https://cdn-images-1.medium.com/max/1600/0*fU8XFt-NCMZGAWND.\" width=\"600\">\r\n",
        "\r\n",
        "Gradient descent with two variables ideally looks like this:\r\n",
        "<img src=\"https://blog.paperspace.com/content/images/2019/09/F1-02.large.jpg\" width=\"600\">\r\n",
        "\r\n",
        "Gradient descent is an iterative algorithm for finding the **local minimum** of a differentiable function.\r\n",
        "- Choose an initial value of $\\hat{\\theta}$ and a **learning rate** $r$.\r\n",
        "- For each iteration $k$, do:\r\n",
        "$$\\hat{\\theta} \\leftarrow \\hat{\\theta} - r\\cdot\\frac{\\partial J(\\hat{\\theta})}{\\partial \\theta}.$$\r\n",
        "- The partial derivative of the cost function is given by\r\n",
        "$$\r\n",
        "\\frac{\\partial J(\\hat{\\theta})}{\\partial \\theta} = \\frac{2}{m}\\cdot\\textbf{X}^T\\cdot(\\textbf{X}\\cdot\\theta - \\textbf{y}).\r\n",
        "$$\r\n",
        "- **Verify the formula of partial derivative asuuming there is one input feature.**\r\n",
        "\r\n",
        "- End iteration if certain stop criteria is reached, such as:\r\n",
        "    - Value of $\\hat{\\theta}$ becomes stable.\r\n",
        "    - Certain iteration amount is reached."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clRpPwu-x1Yp"
      },
      "source": [
        "# Choose a random initial value for each parameter.\r\n",
        "\r\n",
        "theta = np.array([10, 1, 0.1]).reshape([3, 1])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yP5gFqHx1bM",
        "outputId": "5cf9e148-e3b5-406a-b7b4-dde9c5fce33c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Perform gradient descent once.\r\n",
        "# Choose a learning rate r\r\n",
        "r = 0.00001\r\n",
        "\r\n",
        "# 1. Calculate the gradient\r\n",
        "gradient = 2 / 5 * (X.T).dot(X.dot(theta) - y)\r\n",
        "print(\"gradient:\", gradient)\r\n",
        "\r\n",
        "# 2. Update the parameters\r\n",
        "theta = theta - r * gradient\r\n",
        "print(\"theta:\", theta)\r\n",
        "\r\n",
        "# 3. (optional) Show the MSE cost with new parameter values\r\n",
        "\r\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gradient: [[  44.2]\n",
            " [4052. ]\n",
            " [3457. ]]\n",
            "theta: [[9.999558]\n",
            " [0.95948 ]\n",
            " [0.06543 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPqDCTznx1dq"
      },
      "source": [
        "# Perform gradient descent multiple times\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sfCU6C33reK"
      },
      "source": [
        "# Plot the learning curve.\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXOFqVwlx1gQ"
      },
      "source": [
        "**Discussion**\r\n",
        "1. Change $r$ to 0.000001 and 1. Observe the MSE curve.\r\n",
        "2. Do the initial parameter values matter?\r\n",
        "3. How to determine when to stop the iteration?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEnnJd4Qx1ii"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVWfuoUHx1lB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVfSS1dgx1np"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}