{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week06_PolynomialRegression",
      "provenance": [],
      "authorship_tag": "ABX9TyNhizev2cjvO1W5m1GYEIRM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ch00226855/CMP414765Spring2021/blob/main/Week06_PolynomialRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow-7FTa_5eHX"
      },
      "source": [
        "# Week 6\r\n",
        "# Polynomial Regression\r\n",
        "\r\n",
        "What if the data is actually more complex than a simple straight line? A simple way to make the model more flexible is to add powers of original features as new features, then train a linear model on this extended set of features. This technique is called **Polynomial Regression**.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHq-sx-75kam"
      },
      "source": [
        "## Polynomial Regression: Model Representation\r\n",
        "- The polynomial regression model assumes that the relationship between the input variable $X$ and the output variable $Y$ can be approximately described as\r\n",
        "$$Y \\approx f(X) = \\theta_0 + \\theta_1 X + \\theta_2 X^2 +\\cdots + \\theta_d X^d.$$\r\n",
        "- There is a single input variable $X$, which appears in each term expect for the constant term.\r\n",
        "- The degree $d$ is determined by the researcher. In pratice $d$ is rarely above 4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCw6JMDu5kc9"
      },
      "source": [
        "To illustrate the similarities and differences between linear regression and polynomial regression, let's consider the following dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3uf4kpX5kfe"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6WOTVHg5kiK"
      },
      "source": [
        "# Generate a data set\r\n",
        "m = 100\r\n",
        "X = 6 * np.random.rand(m, 1) - 3\r\n",
        "y = 0.5 * X ** 2 + X + 2 + np.random.randn(m, 1)\r\n",
        "plt.plot(X, y, 'c.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPAB3k3z5kkt"
      },
      "source": [
        "# Find the best linear fit of the data, and calculate the MSE.\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzT-7dPT5knf"
      },
      "source": [
        "## Polynomial Regression: Training Algorithm\r\n",
        "The polynomial regression can actually be treated as multilinear regression with feature transformation in the following way:\r\n",
        "1. Transform the original feature $X$ to a set of new features:\r\n",
        "    - $Z_1 = X$\r\n",
        "    - $Z_2 = X^2$\r\n",
        "    - $Z_3 = X^3$\r\n",
        "    - $\\cdots$\r\n",
        "    - $Z_d = X^d$\r\n",
        "2. Then the model can be expressed as a multilinear model on $Z$'s:\r\n",
        "$$Y \\approx \\theta_0 + \\theta_1Z_1 + \\theta_2Z_2 +\\cdots + \\theta_dZ_d$$.\r\n",
        "3. Train the model as multilinear regression (use the normal equation or gradient descent)\r\n",
        "    - To use the normal equation, the matrix $\\textbf{X}$ and $\\textbf{y}$ should be defined as\r\n",
        "    $$\\textbf{X} = \\begin{pmatrix}\r\n",
        "    1 & x^{(1)} & (x^{(1)})^2 & \\cdots & (x^{(1)})^d \\\\\r\n",
        "    1 & x^{(2)} & (x^{(2)})^2 & \\cdots & (x^{(2)})^d \\\\\r\n",
        "    \\vdots & \\vdots & \\vdots &\\ddots & \\vdots \\\\\r\n",
        "    1 & x^{(m)} & (x^{(m)})^2 & \\cdots & (x^{(m)})^d \\\\\r\n",
        "    \\end{pmatrix}, \\textbf{y} = \\begin{pmatrix}\r\n",
        "    y^{(1)}\\\\\r\n",
        "    y^{(2)}\\\\\r\n",
        "    \\vdots\\\\\r\n",
        "    y^{(m)}\r\n",
        "    \\end{pmatrix}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65hm1LT75kqQ"
      },
      "source": [
        "# Let's consider a polynomial model of degree 2.\r\n",
        "# First, create data matrix X and y.\r\n",
        "from sklearn.preprocessing import PolynomialFeatures\r\n",
        "poly_features = PolynomialFeatures(degree=2, include_bias=False)\r\n",
        "poly_features.fit(X)\r\n",
        "X_poly = poly_features.transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnfKodcb6vxN"
      },
      "source": [
        "# Use sci-kit learn to train the polynomial model.\r\n",
        "from sklearn.linear_model import LinearRegression\r\n",
        "model_pr = LinearRegression()\r\n",
        "model_pr.fit(X_poly, y)\r\n",
        "print(model_pr.coef_, model_pr.intercept_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsShT3RZ69eD"
      },
      "source": [
        "# Calculate the MSE of the degree-2 polynomial regression\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlU0BTcQ6-I8"
      },
      "source": [
        "# Visualize the regression curve\r\n",
        "plt.plot(X, y, 'c.') # Plot points from training data\r\n",
        "x_coordinates = np.linspace(-3, 3, 100) # create a list of x in interval [-3, 3]\r\n",
        "# Use the model to predict the corresponding y value\r\n",
        "x_coordinates_poly = poly_features.transform(x_coordinates.reshape([-1, 1]))\r\n",
        "y_coordinates = model_pr.predict(x_coordinates_poly)\r\n",
        "# Plot the points\r\n",
        "plt.plot(x_coordinates, y_coordinates, 'm-') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R0TGaWr5ksx"
      },
      "source": [
        "# Apply the normal equation to find the degree 2 polynomial fit of X and y\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd2tVzlt5kvi"
      },
      "source": [
        "## Polynomial Regression: Overfitting\r\n",
        "Polynomial regression with greater $d$ tends to fit the training data better. However, the performance may not carry to new data.\r\n",
        "<img src=\"https://docs.aws.amazon.com/machine-learning/latest/dg/images/mlconcepts_image5.png\" width=\"600\">\r\n",
        "<img src=\"https://miro.medium.com/fit/c/1838/551/0*Wup-0b5KI6-8cJB4.jpg\" width=\"600\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4fIuAwm5kyj"
      },
      "source": [
        "# Train a degree 20 polynomial to fit X and y\r\n",
        "poly_features = PolynomialFeatures(degree=20, include_bias=False)\r\n",
        "# poly_features.fit(X)\r\n",
        "# X_poly = poly_features.transform(X)\r\n",
        "X_poly = poly_features.fit_transform(X)\r\n",
        "\r\n",
        "model_pr = LinearRegression()\r\n",
        "model_pr.fit(X_poly, y)\r\n",
        "predictions = model_pr.predict(X_poly)\r\n",
        "mse = mean_squared_error(y, predictions)\r\n",
        "print(\"MSE:\", mse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf5rmw_S5k1Z"
      },
      "source": [
        "plt.plot(X, y, 'c.')\r\n",
        "x_coordinates = np.linspace(-3, 3.05, 100)\r\n",
        "x_coordinates_poly = poly_features.transform(x_coordinates.reshape([-1, 1]))\r\n",
        "y_coordinates = model_pr.predict(x_coordinates_poly)\r\n",
        "plt.plot(x_coordinates, y_coordinates, 'm-')\r\n",
        "# plt.ylim(0, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrnW5EPO5k4T"
      },
      "source": [
        "## Identify Overfitting:\r\n",
        "1. Train-test split\r\n",
        "2. Learning curve\r\n",
        "3. Cross validation\r\n",
        "4. Visualization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "royLvU255k69"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WO3neTi5k9p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1iV-Z2V5lAp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVdqeEAw5lDU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzX1eDSs5lF7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMpdegsY5lIv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wyNjhsm5lLO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNJ96HlJ5lOH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}